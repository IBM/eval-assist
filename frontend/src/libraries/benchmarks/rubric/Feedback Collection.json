{
    "name": "Feedback Collection",
    "description": "The Feedback Collection is a dataset designed to induce fine-grained evaluation capabilities into language models.\n\nCorrelation/Agreement for this dataset is calculated on gpt4 ratings.",
    "link": "https://github.com/prometheus-eval/prometheus-eval/blob/main/eval/benchmark/data/feedback_collection_test.json",
    "type": "rubric",
    "dataset": {
        "name": "Feedback Collection",
        "description": "loren ipsum"
    },
    "tags": [
        "RAG"
    ],
    "criteriaBenchmarks": [
        {
            "name": "Overall",
            "evaluatorBenchmarks": [
                {
                    "evaluator_id": "meta-llama/llama-3-70b-instruct",
                    "laaj_version": "v0.0.7-alpha",
                    "results": {
                        "agreement": 0.476,
                        "p_bias": 0.157,
                        "pearson": 0.77
                    }
                },
                {
                    "evaluator_id": "kaist-ai/prometheus-8x7b-v2",
                    "laaj_version": "v0.0.7-alpha",
                    "results": {
                        "agreement": 0.422,
                        "p_bias": 0.44,
                        "pearson": 0.764
                    }
                },
                {
                    "evaluator_id": "meta-llama/llama-3-8b-instruct",
                    "laaj_version": "v0.0.7-alpha",
                    "results": {
                        "agreement": 0.361,
                        "p_bias": 0.014,
                        "pearson": 0.692
                    }
                },
                {
                    "evaluator_id": "mistralai/mixtral-8x7b-instruct-v01",
                    "laaj_version": "v0.0.7-alpha",
                    "results": {
                        "agreement": 0.329,
                        "p_bias": 0.109,
                        "pearson": 0.558
                    }
                }
            ]
        }
    ]
}